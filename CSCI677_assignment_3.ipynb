{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment you will practice putting together an image classification pipeline based on CNNs for [CIFAR-10 and/or CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. The goals of this assignment are as follows:\n",
    "\n",
    "\n",
    "\n",
    "*   Understand the components of a CNN model.\n",
    "*   Understand how to modify a standard CNN model towards a specific task.\n",
    "*   Implement and train a LeNet-5 model.\n",
    "*   Implement and train a VGGNet model.\n",
    "*   Implement and train a ResNet model.\n",
    "*   Understand the differences and tradeoffs between these models.\n",
    "\n",
    "Please fill in all the **TODO** code blocks. Once you are ready to submit:\n",
    "\n",
    "* Export the notebook `CSCI677_assignment_3.ipynb` as a PDF `[Your USC ID]_CSCI677_assignment_3.pdf`\n",
    "* Submit your PDF file through [Blackboard](https://blackboard.usc.edu/)\n",
    "\n",
    "Please make sure that the notebook have been run before exporting PDF, and your code and all cell outputs are visible in your submitted PDF. Regrading request will not be accepted if your code/output is not visible in the original submission. Thank you!"
   ],
   "metadata": {
    "id": "pMblnPgI4pQh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In case you haven't installed PyTorch yet, run the following command to install torch and torchvision."
   ],
   "metadata": {
    "id": "C3_vNZ33-kcr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch torchvision"
   ],
   "metadata": {
    "id": "vhaHm9fe-vYH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Data Preparation**\n",
    "\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is a well known dataset composed of 60,000 colored 32x32 images in 10 classes, with 6000 images per class. The utility function `cifar10()` returns the entire CIFAR-10 dataset as a set of four Torch tensors:\n",
    "* `x_train` contains all training images (real numbers in the range  [0,1] )\n",
    "* `y_train` contains all training labels (integers in the range  [0,9] )\n",
    "* `x_test` contains all test images\n",
    "* `y_test` contains all test labels\n",
    "\n",
    "This function automatically downloads the CIFAR-10 dataset the first time you run it.\n",
    "\n",
    "[CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) is just like the CIFAR-10 dataset, except it has 100 classes containing 600 images each. Below we provided wrapper classes for CIFAR-10 and CIFAR-100 datasets. You can choose one or both of them for training your CNNs. If you choose one of them, use the same one to train all your models."
   ],
   "metadata": {
    "id": "4ucCCRiq6BVp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qh-a1XGO9qNF"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CIFAR10Dataset:\n",
    "    def __init__(self, batch_size=128, root=\"data\"):\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))]\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.training_data = datasets.CIFAR10(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        self.train_dataloader = DataLoader(self.training_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.test_data = datasets.CIFAR10(\n",
    "            root=root,\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        self.test_dataloader = DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        self.classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "class CIFAR100Dataset:\n",
    "    def __init__(self, batch_size=128, root=\"data\"):\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))]  # CIFAR-100 normalization values\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.training_data = datasets.CIFAR100(\n",
    "            root=root,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        self.train_dataloader = DataLoader(self.training_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.test_data = datasets.CIFAR100(\n",
    "            root=root,\n",
    "            train=False,\n",
    "            download=False,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        self.test_dataloader = DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        self.classes = self.training_data.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet-5 (20 pts)\n",
    "LeNet-5, introduced by Yann LeCun in 1998, is a relatively shallow network. It consists of two convolutional layers and two fully connected layers. LeNet-5 was designed for handwritten digit recognition tasks and had a relatively small number of parameters."
   ],
   "metadata": {
    "id": "ZalEn-ux99oz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement LeNet-5 (10 pts)\n",
    "Classical LeNet-5 architecture is as follows:\n",
    "\n",
    "\n",
    "![LeNet-5 Architecture](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-52-17.png)\n",
    "\n",
    "\n",
    "Its input is 32x32x1 because it was designed for greyscale images of 32x32. However, inputs from CIFAR-10/100 are colored 32x32 images, therefore you need to modify it. Requirements:\n",
    "* The model should take inputs of 32x32x3 and output a vector of dimension equal to the number of classes (10 for CIFAR-10 and 100 for CIFAR-100).\n",
    "* The model should have 2 convolutional layers and 3 fully connected layers::\n",
    "\n",
    "  (Convolution -> Sigmoid -> Average Pooling) ->\n",
    "\n",
    "  (Convolution -> Sigmoid -> Average Pooling) ->\n",
    "\n",
    "  Flattening ->\n",
    "\n",
    "  (Linear -> Sigmoid) ->\n",
    "\n",
    "  (Linear -> Sigmoid) -> Linear.\n",
    "* Use 5x5 convolutional filters.\n",
    "\n",
    "**Hint**: you can use nn.Sequential() to simplify your implementation."
   ],
   "metadata": {
    "id": "d2nZE65W_PBU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdieMH2P9U1W"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization (10 pts)\n",
    "Visualize your LeNet-5 using Tensorboard or Netron. Make sure each component of your model is visible."
   ],
   "metadata": {
    "id": "p8K9lATeGM3x"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO"
   ],
   "metadata": {
    "id": "HCDM-yCiHGux"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGGNet (20 pts)\n",
    "VGGNet, or Visual Geometry Group Network, is a deep convolutional neural network (CNN) architecture introduced in 2014, known for its simplicity and depth. It employs a uniform structure with small 3x3 convolutional kernels throughout its layers, emphasizing the advantages of increased depth in CNNs. In comparison to AlexNet, VGGNet's uniformity and architectural simplicity make it an influential reference model in deep learning, demonstrating the effectiveness of deeper networks and smaller convolutional kernels for image classification tasks.\n",
    "\n",
    "In this section, you will implement a variant of VGGNet for CIFAR-10/100."
   ],
   "metadata": {
    "id": "hQySHxwXFETY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement VGGNet (20 pts)\n",
    "Classical VGGNet architecture is as follows:\n",
    "\n",
    "\n",
    "![VGGNet Architecture](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzxRI1qHXjiVXla-_NiMBA.png)\n",
    "\n",
    "\n",
    "It has 13 convolutional layers and 3 fully connected layers. Its input is 224x224x3 because it was designed for ImageNet. Again, inputs from CIFAR-10/100 are colored 32x32 images, therefore you need to modify it. Requirements:\n",
    "* The model should take inputs of 32x32x3 and output a vector of dimension equal to the number of classes (10 for CIFAR-10 and 100 for CIFAR-100).\n",
    "* The model should have 10 convolutional layers and 3 fully connected layers:\n",
    "\n",
    " (Conv -> ReLU -> Conv -> ReLU -> Max Pool) ->\n",
    "\n",
    " (Conv -> ReLU -> Conv -> ReLU -> Max Pool) ->\n",
    "\n",
    " (Conv -> ReLU -> Conv -> ReLU -> Conv -> ReLU -> Max Pool) ->\n",
    "\n",
    " (Conv -> ReLU -> Conv -> ReLU -> Conv -> ReLU -> Max Pool) ->\n",
    "\n",
    " Flattening ->\n",
    "\n",
    " (Linear -> ReLU -> Dropout) ->\n",
    "\n",
    " (Linear -> ReLU -> Dropout) -> Linear.\n",
    "* Use 3x3 convolutional filters with padding 1.\n",
    "\n",
    "**Hint**: you can use nn.Sequential() or define make_layer() function by yourself to simplify your implementation."
   ],
   "metadata": {
    "id": "K43x5buyHQiV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGGNet, self).__init__()\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        return x"
   ],
   "metadata": {
    "id": "XK_TBIcbIi2N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet (20 pts)\n",
    "ResNet, short for Residual Network, was introduced in 2015 by Kaiming He et al. At its core, ResNet introduces the concept of residual blocks, which allows gradients to flow directly through the network's many layers. In comparison to earlier architectures like AlexNet, ResNet's approach demonstrates the transformative power of residual connections.\n",
    "\n",
    "In this section, you will implement ResNet-18 for CIFAR-10/100."
   ],
   "metadata": {
    "id": "R4o3qwInhsnT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement Residual Block (10 pts)\n",
    "The Residual Block is a crucial component in ResNet. It works by introducing a shortcut connection, also known as a skip connection, alongside a regular neural network layer. This shortcut connection enables the flow of information directly from one layer to another, bypassing some intermediate layers.\n",
    "\n",
    "The key idea is to learn a residual function, which represents the difference between the desired output and the current output of the block. By doing so, the block aims to make the output closer to what it should be. This approach mitigates the vanishing gradient problem, which can occur in very deep networks, making it easier to train deep models effectively.\n",
    "\n",
    "![Residual Block](https://miro.medium.com/v2/resize:fit:1140/format:webp/1*6WlIo8W1_Qc01hjWdZy-1Q.png)\n",
    "\n",
    "\n",
    "The weight layer usually consists of a convolutional layer and a batch normalization layer. The batch normalization layer, often abbreviated as BatchNorm, normalizes the input of a neural network layer across a mini-batch of data during training. BatchNorm not only accelerates convergence but also acts as a form of regularization, reducing the risk of overfitting. In PyTorch, it is implemented by nn.BatchNorm2d().\n",
    "\n",
    "You are asked to implement the residual block with the following requirements:\n",
    "* The residual block takes input of size n * n * `in_channels` and output m * m * `out_channels` with m = (n-1) / `stride` + 1\n",
    "* The residual function consists of the following components:\n",
    "\n",
    "  Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm\n",
    "\n",
    "  where Conv means 3x3 convolutional filters with padding 1. If `stride` != 1, set stride for the first Conv.\n",
    "* The shortcut should be identity if `in_channels` == `out_channels` and `stride` == 1. Otherwise, it should be a convolutional layer with kernel_size=1 and stride=`stride`.\n",
    "* After adding the residual function and the shortcut, apply another ReLU activation."
   ],
   "metadata": {
    "id": "_LQbwuLUj1mO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        return x"
   ],
   "metadata": {
    "id": "56act4Fdtbxl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement ResNet-18 (10 pts)\n",
    "ResNet-18 is part of the ResNet family, known for its exceptional depth and performance in image classification tasks. It consists of 18 layers, beginning with one convolutional layer, followed by a few residual blocks, and ending with a fully-connected layer. Here is a glimpse of its architecture:\n",
    "\n",
    "\n",
    "![ResNet-18](https://www.researchgate.net/profile/Sajid-Iqbal-13/publication/336642248/figure/fig1/AS:839151377203201@1577080687133/Original-ResNet-18-Architecture.png)\n",
    "\n",
    "\n",
    "You are asked to implement ResNet-18 for CIFAR-10/100. Requirements:\n",
    "* The model should take inputs of 32x32x3 and output a vector of dimension equal to the number of classes (10 for CIFAR-10 and 100 for CIFAR-100).\n",
    "* The model should begin with a convolutional layer with kernel_size=3 and padding=1:\n",
    "\n",
    "  Conv -> BatchNorm -> ReLU\n",
    "\n",
    "  The output size should be 32x32x64.\n",
    "* After the first layer, append with 8 residual blocks such that the output size changes as follows:\n",
    "  \n",
    "  32x32x64 -> 32x32x64 -> 32x32x64 -> 16x16x128 -> 16x16x128 -> 8x8x256 -> 8x8x256 -> 4x4x512 -> 4x4x512\n",
    "* The model should end with average pooling (kernel_size=4), flattening, and a fully-connected layer.\n"
   ],
   "metadata": {
    "id": "2RYB3dvEzavj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        # TODO\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        return x"
   ],
   "metadata": {
    "id": "znZV9y734trg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Neural Networks (40 pts)\n",
    "In this section, you will implement a `Trainer` class, use it to train the models that you defined previously, and evaluate them."
   ],
   "metadata": {
    "id": "urxGfv7h7YPG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check CUDA and GPUs\n",
    "The following code helps you check if CUDA is available and lists the available GPUs."
   ],
   "metadata": {
    "id": "M9anAco48Aht"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYlsO8GA90vz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "    # Get the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "\n",
    "    # Set the current GPU device\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Current GPU device: {device} - {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complete the Trainer Class (15 pts)\n",
    "Fill-in all the TODOs"
   ],
   "metadata": {
    "id": "WW7k1eFy_c1U"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jD3MKbt9vn1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, dataset, net, optimizer, loss_function=nn.CrossEntropyLoss(),\n",
    "                 device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.dataset = dataset\n",
    "        self.net = net.to(device)\n",
    "        self.lossFunction = loss_function\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        # TODO (5 pts): complete training loop\n",
    "        pass\n",
    "\n",
    "    def compute_test_accuracy(self):\n",
    "        # TODO (5 pts): compute classification accuracy based on test data\n",
    "        pass\n",
    "\n",
    "    def train(self, num_epochs=20):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch()\n",
    "            # TODO (5 pts): print loss for every epoch, print test accuracy for every 5 epochs\n",
    "            # Feel free to record the training process for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training (5 pts)\n",
    "Follow these steps:\n",
    "* Create the model, the dataset, and the optimizer.\n",
    "* Configure the trainer.\n",
    "* Compute and print test accuracy before training.\n",
    "* Train the model.\n",
    "* Compute and print test accuracy after training."
   ],
   "metadata": {
    "id": "Rj6DxGwvALFu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GLSfjg89955p"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation using Confusion Matrix (5 pts)\n",
    "A confusion matrix is a fundamental tool for evaluating the performance of classification models. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class.\n",
    "\n",
    "You are asked to evaluate your trained model by computing and printing the confusion matrix. You can either compute it by yourself or use sklearn.metrics.confusion_matrix()."
   ],
   "metadata": {
    "id": "FX2-yUziAi5w"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO"
   ],
   "metadata": {
    "id": "giA5Kg53DBwX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Observations (15 pts)\n",
    "Write down your observations regarding the results you obtained throughout this assignment. Here are some suggestions:\n",
    "* **Accuracy and Loss Curves**: Plot and compare the training and validation accuracy and loss curves for each model. This helps visualize how well each model is learning over time and whether they are overfitting or underfitting.\n",
    "* **Top Misclassified Images**: Examine the classes that are most frequently misclassified by each model. This can provide insights into the types of images that are challenging for each model and may suggest areas for improvement.\n",
    "* **Feature Visualization**: Visualize the feature maps or activations of intermediate layers in each CNN. This can help you understand what features or patterns each model is learning and whether they differ in terms of learned representations.\n",
    "* **Robustness Testing**: Assess the robustness of each model by introducing noise, transformations, or adversarial examples to the test data. This can help identify which models are more resilient to perturbations.\n",
    "* **Runtime and Resource Usage**: Compare the training time and resource usage (e.g., GPU memory) of each model.\n",
    "* **Hyperparameter Tuning**: Analyze the impact of hyperparameters (learning rates, batch sizes, etc.) on training speed and convergence.\n",
    "* **Model Size and Efficiency**: Analyze the trade-off between model size and accuracy for each model.\n",
    "* **Ablation Studies**: Conduct ablation studies by removing or modifying specific components (e.g., dropout, batch normalization, etc.) of each model to understand their contributions to performance.\n",
    "\n",
    "You don't need to follow them. Feel free to write down any observation you have, or to use tools like Tensorboard to support your observations. You are also welcome to give comments on the design of the assignment."
   ],
   "metadata": {
    "id": "kdkvCp5bDVe8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **TODO: write down your observations**"
   ],
   "metadata": {
    "id": "iIDgYVOrGcZI"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
